# enter object store and API settings and save as processing.yaml.
# the options listed below should work for the test api-server, set up with the ./run command
---
s3:
    access_key_id: "minio"
    secret_access_key: "miniostorage"
    default_bucket: "cacophony"
    endpoint: "http://127.0.0.1:9001"
    tls: "False"

api_url: "http://127.0.0.1:2008/api/fileProcessing"

# classify option allows you to turn off the classifier for test purposes if the classifier is not set up
classify: True

# Setup classifier_pipeline [https://github.com/TheCacophonyProject/classifier-pipeline]
classify_command_dir: "../classifier_pipeline"
# Relative paths in this command are relative from the classify_command_dir.
# Should be run using the classifier_pipeline python3.6 virtual environment.
classify_command: "venv/bin/python classify.py --processor-folder {folder} {source}"
tagging:
    # This is the minimum confidence (for an animal rating) a track should have to be considered a possible animal
    min_confidence: .4

    # This is the minimum confidence a track should have in order to tag as animal
    min_tag_confidence: .8

    # Classifications with a novelty above this value will be ignored for tagging.
    max_tag_novelty: .7

    # This is the minimum difference in confidence between next choice a track should have in order to tag it as the chosen animal
    min_tag_clarity: .2

    # If the same animal has clearly been identified in the video then a reduced clarity is acceptable.
    min_tag_clarity_secondary: .05

    # This is the minimum length of a track.
    min_frames: 3

    # If tracks moves this many pixels in any direction then we shall assume it isn't a false positive
    animal_movement: 50


audio:
    convert_workers: 2
    analysis_workers: 2

    # The command will be called to perform analysis on audio recordings (e.g. Cacophony Index, speech detection)
    analysis_command: 'docker run -it -v "{folder}":/io cacophonyproject/audio-analysis /io/"{basename}"'
